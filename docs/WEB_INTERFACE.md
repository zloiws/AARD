# Веб-интерфейс AARD

## Обзор

Веб-интерфейс AARD построен на HTMX + Jinja2 для легкого и быстрого взаимодействия с LLM. Интерфейс предоставляет интуитивно понятный чат с поддержкой разных типов задач.

## Архитектура

### Технологии

- **HTMX** - для динамических обновлений без JavaScript
- **Jinja2** - шаблонизация HTML
- **FastAPI** - веб-сервер
- **TailwindCSS-подобный CSS** - встроенные стили

### Компоненты

1. **Pages Router** (`backend/app/api/routes/pages.py`)
   - Главная страница `/`
   - Рендеринг шаблонов

2. **Chat Router** (`backend/app/api/routes/chat.py`)
   - API endpoint для чата
   - Поддержка HTML фрагментов для HTMX

3. **Templates** (`frontend/templates/`)
   - `base.html` - базовый шаблон
   - `index.html` - главная страница с чатом
   - `message_fragment.html` - фрагмент сообщения для HTMX

## Использование

### Запуск

```bash
# Активировать окружение
.\activate.ps1

# Запустить приложение
python backend/run.py

# Открыть в браузере
# http://localhost:8000/
```

### Интерфейс

1. **Выбор типа задачи**
   - Общий чат
   - Генерация кода
   - Анализ кода
   - Рассуждения
   - Планирование
   - Генерация текста

2. **Настройка температуры**
   - Диапазон: 0.0 - 2.0
   - По умолчанию: 0.7

3. **Отправка сообщения**
   - Введите текст в поле ввода
   - Нажмите "Отправить" или Enter
   - Shift+Enter для новой строки

## Особенности

### Выбор модели

**Ручной выбор:**
- В выпадающем списке "Модель" можно выбрать конкретную модель
- Доступность модели отображается значками ✓ (доступна) или ✗ (недоступна)
- Если выбрана недоступная модель, появится предупреждение

**Автоматический выбор:**
- Если выбрано "Автоматический выбор", система подберет модель на основе типа задачи:
  - **code_generation** / **code_analysis** → qwen3-coder (если доступна)
  - **reasoning** / **planning** → deepseek-r1 (если доступна)
  - **general_chat** / **text_generation** → deepseek-r1 (если доступна)
- Если предпочтительная модель недоступна, будет выбран первый доступный инстанс

### HTMX интеграция

Используется HTMX для динамических обновлений:

- Форма отправки сообщения через `hx-post`
- Автоматическое добавление ответов в чат
- Индикатор загрузки
- Обработка ошибок

### Адаптивный дизайн

- Современный градиентный дизайн
- Адаптивная верстка
- Плавные анимации
- Подсветка кода

## Структура шаблонов

```
frontend/templates/
├── base.html              # Базовый шаблон со стилями
├── index.html             # Главная страница чата
└── message_fragment.html  # Фрагмент сообщения для HTMX
```

## API Endpoints

### GET /

Главная страница с веб-интерфейсом.

**Response:** HTML страница с чатом

### POST /api/chat/

Отправка сообщения (поддерживает HTML фрагменты для HTMX).

**Request (JSON):**
```json
{
  "message": "Напиши функцию",
  "task_type": "code_generation",
  "temperature": 0.7
}
```

**Response (HTML для HTMX):**
```html
<div class="message assistant">
    <div class="message-content">...</div>
    <div class="message-meta">...</div>
</div>
```

**Response (JSON):**
```json
{
  "response": "...",
  "model": "...",
  "task_type": "...",
  "duration_ms": 1234
}
```

## Кастомизация

### Изменение стилей

Стили встроены в `base.html`. Для изменений:

1. Отредактируйте `<style>` блок в `base.html`
2. Или вынесите стили в отдельный CSS файл в `frontend/static/`

### Добавление новых типов задач

1. Добавьте тип в `TaskType` enum в `ollama_client.py`
2. Обновите mapping в `OllamaClient.task_type_mapping`
3. Добавьте опцию в select в `index.html`

## Следующие шаги

- [ ] WebSocket для streaming ответов
- [ ] История чата (сохранение в БД)
- [ ] Подсветка синтаксиса кода (highlight.js)
- [ ] Экспорт чата
- [ ] Темная тема
- [ ] Мобильная оптимизация

