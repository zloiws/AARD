**ToDo-список — это не просто лист задач, это живой, динамический контракт между агентом, системой и человеком**. Его управление должно быть строго формализовано, иначе система превратится в хаотичный набор действий без подотчётности.

---

# Рекомендации: Управление ToDo-Списком как Ключевой Механизм Контроля и Самосовершенствования

## 1. ToDo-Список — это Жизненный Цикл Задачи: Четкие Статусы и Владельцы

Ваш ToDo-список должен быть не статическим списком дел, а **управляемым workflow с чёткими фазами жизненного цикла**. Каждая задача проходит через несколько состояний, и переход между ними требует явного действия или одобрения.

### Жизненный Цикл Задачи (Task Lifecycle)

| Статус | Описание | Кто может установить? |
| :--- | :--- | :--- |
| `DRAFT` | Задача создана моделью-планировщиком, но ещё не согласована. Это черновик плана. | Только **Planner Agent** (модель размышлений). |
| `PENDING_APPROVAL` | План отправлен на утверждение. Требуется внешнее подтверждение для критических шагов. | Автоматически **Planner Agent** при достижении порога риска. |
| `APPROVED` | Задача утверждена (человеком или автоматизированным валидатором). Разрешено выполнение. | **Human-in-the-Loop** или **Validator Agent**. |
| `IN_PROGRESS` | Задача выполняется. Инструмент запущен, код исполняется. | Автоматически при начале выполнения. |
| `COMPLETED` | Задача успешно завершена, результат проверен. | **Validator Agent** (после успешной проверки). |
| `FAILED` | Задача завершилась с ошибкой. Требуется анализ. | **Validator Agent** или **Executor**. |
| `ON_HOLD` | Выполнение приостановлено (ожидание данных, человека, внешнего события). | **Planner Agent**, **Human**, **System Monitor**. |
| `CANCELLED` | Задача отменена (по решению человека или из-за изменения условий). | **Human**, **Planner Agent** (если цель достигнута другим путём). |

**Ключевой момент:** Переход из `DRAFT` в `PENDING_APPROVAL` должен быть **автоматическим** для всех задач, связанных с:
- Созданием новых агентов или инструментов.
- Изменением существующих артефактов (кода, промптов, базы знаний).
- Доступом к защищённым данным или внешним API.
Это реализует ваше требование "внешнее подтверждение на критические шаги".

## 2. Кто Утверждает, Изменяет и Контролирует?

Это центральный вопрос. В системе должна быть **иерархия полномочий**:

| Действие | Кто может инициировать? | Кто может утвердить/подтвердить? | Комментарий |
| :--- | :--- | :--- | :--- |
| **Создание нового ToDo-списка** | **Planner Agent** | **Human** (для первого уровня) / **Validator Agent** (для повторных итераций) | Первый план всегда требует человеческого утверждения. Последующие — могут утверждаться автоматически, если они являются частью цикла самокоррекции по уже утверждённому шаблону. |
| **Изменение списка (добавление/удаление задач)** | **Planner Agent** (при самокоррекции) | **Human** (если изменение затрагивает критические шаги) / **Validator Agent** (для некритических изменений) | Например, если парсер не смог собрать данные, Planner может добавить задачу "Найти альтернативный источник". Если этот источник — новый сайт, требуется утверждение. |
| **Утверждение списка** | - | **Human** (через UI, например, OpenWebUI) | Утверждение должно быть явным: кнопка "Approve Plan" с возможностью просмотра полного списка. |
| **Принудительная остановка/отмена** | **Human**, **System Monitor** (при исчерпании ресурсов) | - | Человек всегда имеет право в любой момент отменить выполнение. |
| **Автоматическое обновление при ошибках** | **Planner Agent** | **Validator Agent** | После получения статуса `FAILED`, Planner генерирует новый список с корректировками. Этот *новый* список снова проходит через `PENDING_APPROVAL`, если содержит новые критические шаги. |

## 3. Механизм Динамического Перепланирования (Replanning)

Система **не должна следовать первоначальному плану слепо**. Ваша идея о дополняемости — ключ к автономии.

**Цикл перепланирования:**
1.  Задача `WebScraper` завершается со статусом `FAILED`.
2.  **Validator Agent** записывает детали ошибки (например, "403 Forbidden", "CSS selector not found").
3.  **Planner Agent** получает эту информацию и переходит в режим анализа.
4.  Он создаёт **новый Draft-план**, который может включать:
    -   Изменение CSS-селектора.
    -   Добавление задачи "Использовать прокси-сервер".
    -   Добавление задачи "Создать Backup Scraper для сайта Y".
5.  Этот новый план отправляется обратно в систему Todo, получает статус `PENDING_APPROVAL` и ждёт подтверждения (человека или валидатора).

Таким образом, ToDo-список становится **эволюционирующим документом**, который адаптируется к реальности.

## 4. Интеграция с Системой Памяти и Контекста

Как указано в ваших воспоминаниях, вы разрабатываете систему памяти [[7]]. ToDo-список должен быть тесно связан с этой системой.

-   **Рабочая память (Working Memory):** Активный ToDo-список для текущей задачи пользователя.
-   **Эпизодическая память (Episodic Memory):** История всех изменений всех ToDo-списков. Это позволяет системе учиться: "В прошлый раз, когда парсер вернул 403, помогло использование User-Agent header. Применим это сейчас."
-   **Процедурная память (Procedural Memory):** Шаблоны успешных планов. Например, шаблон "Price Comparison Task" с предопределёнными шагами и точками утверждения.

## 5. Визуализация и Интерфейс для Человека

Человек должен иметь **единую панель управления (Dashboard)**, где он видит:
-   Текущий активный ToDo-список.
-   Статус каждой задачи (визуальные индикаторы: зелёный, жёлтый, красный).
-   Историю изменений плана.
-   Кнопку "Approve" / "Reject" для списков в состоянии `PENDING_APPROVAL`.
-   Возможность вручную добавить задачу ("Проверить цену в магазине Z") или отменить выполнение.

Использование HTMX или React для этого интерфейса, как вы планируете, является отличным выбором [[69]].

---

**Итоговая Рекомендация:**

Перестаньте думать о ToDo-списке как о простом списке. Превратите его в **управляемый workflow engine** с:
1.  **Чёткими статусами и жизненным циклом.**
2.  **Явным разделением ролей:** Planner создает, Validator проверяет, Human утверждает.
3.  **Автоматизированными триггерами** для утверждения (на основе риска).
4.  **Глубокой интеграцией** с памятью системы для обучения.
5.  **Мощным пользовательским интерфейсом** для контроля.

----------------------------------------------------

# Дополнительные Рекомендации

## 1. Реализация Механизма "Проверка Перед Созданием" (Validate-Then-Build)

**Проблема:** Ваша система планирует создавать новых агентов и инструменты автономно. Без контроля это может привести к бесконечному циклу генерации бессмысленных или конфликтующих компонентов.

**Рекомендация:** Внедрите паттерн **"Validate-Then-Build" (V2B)**. Прежде чем создавать нового агента или инструмент, система должна пройти через формализованную проверку:

1.  **Нужен ли новый агент?** Проверка против существующего реестра (`Agent Registry`). Может, задача решается комбинацией `ResearchAgent` + `WebScraper`, а не требует создания `PriceComparisonAgent`?
2.  **Что он будет делать?** Формальное определение контракта: входные/выходные данные, предусловия, постусловия.
3.  **Какова его ценность?** Оценка ожидаемой выгоды (например, снижение времени выполнения на 50%).
4.  **Есть ли риски?** Анализ потенциальных коллизий с другими агентами, потребление ресурсов, безопасность.

**Реализация:** Создайте специальный **Validator Agent for Agents (AAA - Agent Approval Agent)**. Его задача — принимать промпты вида:
> "Предлагаю создать агент `ImageAnalyzerAgent`. Цель: анализировать скриншоты цен с сайтов. Инструменты: Vision LLM, OCR. Оценка необходимости: высокая, так как текущий `WebScraper` не работает с динамическими графиками. Риски: использование внешнего API, повышенное потребление GPU. Утвердить?"

Этот промпт отправляется на утверждение человеку **или** автоматически, если критерии безопасности и эффективности соблюдены (на основе исторических данных).

**Преимущество:** Предотвращает "инфляцию агентов", обеспечивает осознанное расширение системы.

---

## 2. Введение Концепции "Цифрового Двойника Задачи" (Digital Twin of the Task)

**Проблема:** Текущая задача (например, сравнение цен) — это процесс, который меняется. Нет единой точки истины, где хранится полный контекст.

**Рекомендация:** Для каждой пользовательской задачи создавайте **"Цифрового двойника" (Digital Twin)** — единый объект в базе данных, который объединяет всё:

*   Исходный запрос пользователя.
*   Активный и исторические ToDo-списки.
*   Все сгенерированные артефакты (промпты, код, таблицы).
*   Логи выполнения, ошибки, результаты валидации.
*   Историю взаимодействия с человеком (утверждения, исправления).

**Реализация:** В Postgres создайте таблицу `task_instances` с JSONB-полем `context`, которое служит центральным хранилищем. Все компоненты системы (Planner, Coder, Validator) читают и пишут в этот объект. Это обеспечивает **полную наблюдаемость и воспроизводимость**.

**Преимущество:** Вы можете в любой момент "воссоздать" состояние системы на любой этап выполнения задачи. Это критично для отладки, аудита и обучения.

---

## 3. Механизм "Голосования за План" (Plan Voting / A/B Testing Plans)

**Проблема:** Единственный план, сгенерированный Planner Agent, может быть субоптимальным. Нет механизма сравнения альтернатив.

**Рекомендация:** Реализуйте **A/B тестирование планов** на уровне архитектуры.

1.  При получении сложного запроса, **Planner Agent** генерирует **несколько альтернативных ToDo-списков** (например, 2-3 варианта).
2.  Каждый план оценивается **Validator Agent** по критериям:
    *   Ожидаемое время выполнения.
    *   Количество точек утверждения (меньше = лучше).
    *   Уровень риска.
    *   Эффективность (минимальное количество шагов).
3.  Наилучший план отправляется на утверждение человеку. Человек видит не один, а несколько вариантов и выбирает лучший.

**Реализация:** Используйте LangGraph для параллельного запуска нескольких нод `planning_node`, каждая из которых генерирует свой Draft. Затем нода `voting_node` сравнивает их и выбирает победителя.

**Преимущество:** Система становится более устойчивой и интеллектуальной, способной находить оптимальные стратегии, а не просто первую пришедшую в "голову".

---

## 4. Автоматическое Управление Версионностью Артефактов

**Проблема:** При самосовершенствовании система будет переписывать свои промпты, код и инструменты. Без контроля возможна потеря стабильности.

**Рекомендация:** Внедрите **автоматическую систему управления версиями (Git-like для агентов)**.

*   Каждый артефакт (агент, инструмент, промпт) имеет `version_id`.
*   Любое изменение создаёт новую версию, старая сохраняется.
*   Система ведёт `changelog` с причиной изменения (например, "Исправлена ошибка парсинга для Amazon").
*   Можно легко откатиться к предыдущей версии.
*   Валидатор проверяет, что новая версия не ухудшает метрики (например, не увеличивает количество ошибок).

**Реализация:** Используйте простую внутреннюю систему на базе PostgreSQL (таблицы `artifacts`, `artifact_versions`) или интегрируйте с легковесным Git-сервером (например, Gitea) для хранения кода.

---

## 5. Механизм "Самоаудита" (Self-Audit Loop)

**Проблема:** Как система узнает, что она стала лучше? Только через обратную связь по одной задаче?

**Рекомендация:** Создайте **регулярный цикл самоаудита**.

1.  Раз в день/неделю система выбирает случайные завершённые задачи из своей истории.
2.  Она повторно выполняет их с **текущими версиями своих моделей и промптов**.
3.  Сравнивает результаты:
    *   Было ли решение найдено быстрее?
    *   Требовалось ли меньше утверждений человека?
    *   Было ли качество результата выше?
4.  Генерирует отчёт "Улучшение производительности" и предлагает действия (например, "Версия 2.1 промпта для Coder показала на 30% меньше ошибок. Предлагаю сделать её стандартной.").

**Реализация:** Запланированный workflow в n8n, который запускает "прогон" старых задач в песочнице и собирает метрики.

**Преимущество:** Система получает объективную метрику своего прогресса, а не полагается только на субъективную обратную связь.

---

## 6. Обеспечение Изоляции и Безопасности Выполнения (Execution Isolation)

**Проблема:** Сгенерированный код может быть опасен.

**Рекомендация:** Не просто используйте Docker, а создайте **многоуровневую изоляцию**:

1.  **Уровень 1: Песочница (Sandbox):** Docker-контейнер без доступа к сети и файловой системе хоста.
2.  **Уровень 2: Прокси для сетевых вызовов:** Все HTTP-запросы от агентов идут через ваш прокси-сервер, который логирует, ограничивает частоту и блокирует опасные домены.
3.  **Уровень 3: SPIFFE/SPIRE для A2A:** Как вы уже планируете, все межагентные вызовы должны быть подписаны и зашифрованы с помощью SPIFFE. Это гарантирует, что только доверенные агенты могут общаться между собой [[7]].
4.  **Уровень 4: Политики доступа (RBAC):** Каждый агент имеет роль и ограниченные права (например, `ResearchAgent` может только читать данные, но не записывать).

---

## 7. Поддержка "Частичного Автомата" и Градуированной Автономии

**Проблема:** Жесткое деление "ручной режим / полный автомат" не гибко.

**Рекомендация:** Реализуйте **масштабируемую автономность** (graduated autonomy). Пользователь должен иметь возможность установить уровень доверия:

*   **Уровень 0 (Только чтение):** Система только анализирует и предлагает план, но ничего не выполняет.
*   **Уровень 1 (Подтверждение каждого шага):** Каждая задача в ToDo-списке требует ручного утверждения.
*   **Уровень 2 (Утверждение плана):** Утверждается весь план, затем система выполняет его автономно.
*   **Уровень 3 (Автономия с уведомлением):** Система действует автономно, но отправляет уведомление о начале и завершении.
*   **Уровень 4 (Полный автомат):** Система действует полностью автономно, только логируя.

**Реализация:** Храните `autonomy_level` в контексте задачи. Все точки утверждения проверяют этот уровень перед остановкой.

---

Эти семь дополнительных рекомендаций направлены на то, чтобы превратить вашу систему из прототипа в **промышленную, надежную и по-настоящему самообучающуюся платформу**, способную развиваться под контролем, но без постоянного ручного вмешательства.