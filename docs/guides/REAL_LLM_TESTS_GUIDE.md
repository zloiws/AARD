# –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ä–µ–∞–ª—å–Ω—ã–º —Ç–µ—Å—Ç–∞–º —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ LLM

## –í–∞–∂–Ω–æ: –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∫—ç—à–∞

**–í—Å–µ —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–æ–ª–∂–Ω—ã –æ—Ç–∫–ª—é—á–∞—Ç—å –∫—ç—à** –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ —Ä–µ–∞–ª—å–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤ –∫ –ª–æ–∫–∞–ª—å–Ω—ã–º –º–æ–¥–µ–ª—è–º.

### –ö–∞–∫ –æ—Ç–∫–ª—é—á–∏—Ç—å –∫—ç—à

–ü—Ä–∏ –≤—ã–∑–æ–≤–µ `OllamaClient.generate()` –≤—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–π—Ç–µ `use_cache=False`:

```python
response = await ollama_client.generate(
    prompt="–í–∞—à –ø—Ä–æ–º–ø—Ç",
    task_type=TaskType.PLANNING,
    model=model.model_name,
    server_url=server_url,
    use_cache=False  # ‚ö†Ô∏è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
)
```

### –ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ

1. **–ö—ç—à –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Å—Ç–∞—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã** –≤–º–µ—Å—Ç–æ —Ä–µ–∞–ª—å–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤ –∫ –º–æ–¥–µ–ª—è–º
2. **–†–µ–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–æ–ª–∂–Ω—ã –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ä–∞–±–æ—Ç—É –º–æ–¥–µ–ª–µ–π**, –∞ –Ω–µ –∫—ç—à–∞
3. **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–æ–≤** –¥–æ–ª–∂–Ω–∞ –æ—Ç—Ä–∞–∂–∞—Ç—å —Ä–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–µ–π

## –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤

–ü—Ä–∏ `use_cache=False` –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ª–æ–≥–∏—Ä—É–µ—Ç—Å—è:
- üîÑ –†–ï–ê–õ–¨–ù–´–ô –í–´–ó–û–í –ö LLM (–∫—ç—à –æ—Ç–∫–ª—é—á–µ–Ω)
- ‚úÖ –†–ï–ê–õ–¨–ù–´–ô –û–¢–í–ï–¢ –û–¢ LLM –ø–æ–ª—É—á–µ–Ω (—Å –≤—Ä–µ–º–µ–Ω–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)

## –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤

### –í –ª–æ–≥–∞—Ö –∏—â–∏—Ç–µ:
```
üîÑ –†–ï–ê–õ–¨–ù–´–ô –í–´–ó–û–í –ö LLM (–∫—ç—à –æ—Ç–∫–ª—é—á–µ–Ω)
‚úÖ –†–ï–ê–õ–¨–ù–´–ô –û–¢–í–ï–¢ –û–¢ LLM –ø–æ–ª—É—á–µ–Ω
```

### –ï—Å–ª–∏ –≤–∏–¥–∏—Ç–µ:
```
Using cached response
```
–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∫—ç—à –≤–∫–ª—é—á–µ–Ω –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞—Ä—ã–π –æ—Ç–≤–µ—Ç.

## –¢–∞–π–º–∞—É—Ç—ã –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

–£—á–∏—Ç—ã–≤–∞–π—Ç–µ —Ä–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–µ–π:

```python
TIMEOUTS = {
    "llm_call": 30,  # 30 —Å–µ–∫—É–Ω–¥ –Ω–∞ LLM –≤—ã–∑–æ–≤
    "dialog_message": 20,  # 20 —Å–µ–∫—É–Ω–¥ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å–æ–æ–±—â–µ–Ω–∏—è
    "full_dialog": 120,  # 2 –º–∏–Ω—É—Ç—ã –Ω–∞ –ø–æ–ª–Ω—ã–π –¥–∏–∞–ª–æ–≥
}
```

## –ü—Ä–∏–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞

```python
@pytest.mark.asyncio
@pytest.mark.slow
async def test_real_llm_call(db):
    """–†–µ–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é"""
    ollama_client = OllamaClient()
    
    # –ü–æ–ª—É—á–∏—Ç—å —Å–µ—Ä–≤–µ—Ä –∏ –º–æ–¥–µ–ª—å
    servers = OllamaService.get_all_active_servers(db)
    server = servers[0]
    model = ModelSelector(db).get_planning_model(server=server)
    
    # ‚ö†Ô∏è –í–ê–ñ–ù–û: use_cache=False
    response = await asyncio.wait_for(
        ollama_client.generate(
            prompt="–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç",
            task_type=TaskType.PLANNING,
            model=model.model_name,
            server_url=server.get_api_url(),
            use_cache=False  # –û—Ç–∫–ª—é—á–∏—Ç—å –∫—ç—à
        ),
        timeout=30
    )
    
    assert response.response is not None
    assert len(response.response) > 0
```

## –í—Å–µ –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

**–í—Å–µ –Ω–æ–≤—ã–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ LLM, –¥–æ–ª–∂–Ω—ã:**
1. ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `use_cache=False` –≤ —Ç–µ—Å—Ç–∞—Ö
2. ‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –≤—ã–∑–æ–≤—ã
3. ‚úÖ –£—á–∏—Ç—ã–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–µ–π
4. ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–∞–π–º–∞—É—Ç—ã –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–≥–æ –∂–µ–ª–µ–∑–∞

## –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º

–ü–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º –ø—Ä–æ–≤–µ—Ä—å—Ç–µ:
- [ ] –í—Å–µ —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç `use_cache=False`
- [ ] –í –ª–æ–≥–∞—Ö –≤–∏–¥–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è "–†–ï–ê–õ–¨–ù–´–ô –í–´–ó–û–í –ö LLM"
- [ ] –ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π "Using cached response" –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–∞—Ö
- [ ] –¢–∞–π–º–∞—É—Ç—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

