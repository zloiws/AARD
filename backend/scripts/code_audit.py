"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞—É–¥–∏—Ç–∞ –∫–æ–¥–∞ –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
–≠—Ç–∞–ø 9.1.1: –ü—Ä–æ–≤–µ—Å—Ç–∏ –∞—É–¥–∏—Ç –∫–æ–¥–∞ –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
"""
import sys
import re
import ast
from pathlib import Path
from typing import List, Dict, Set, Any
from collections import defaultdict
import json

# Add backend to path
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

from app.core.logging_config import LoggingConfig

logger = LoggingConfig.get_logger(__name__)


class CodeAuditor:
    """–ê—É–¥–∏—Ç–æ—Ä –∫–æ–¥–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
    
    def __init__(self):
        self.project_root = backend_dir.parent
        self.backend_dir = backend_dir
        self.duplicated_code = []
        self.unused_functions = []
        self.unused_imports = []
        self.deprecated_components = []
        self.all_functions = {}  # {file: {function_name: function_info}}
        self.all_imports = {}  # {file: [imports]}
        self.all_classes = {}  # {file: [classes]}
        
    def find_duplicated_functions(self) -> List[Dict]:
        """–ù–∞–π—Ç–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"""
        duplicates = []
        function_signatures = defaultdict(list)
        
        # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏
        for py_file in self.backend_dir.rglob("*.py"):
            if "__pycache__" in str(py_file) or "migrations" in str(py_file):
                continue
            
            try:
                content = py_file.read_text(encoding="utf-8")
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        # –ü–æ–ª—É—á–∏—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É —Ñ—É–Ω–∫—Ü–∏–∏ (–∏–º—è + –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
                        params = [arg.arg for arg in node.args.args]
                        signature = f"{node.name}({', '.join(params)})"
                        
                        # –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
                        func_lines = content.split('\n')[node.lineno-1:node.end_lineno]
                        func_body_start = '\n'.join(func_lines[:10])  # –ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫
                        
                        function_signatures[signature].append({
                            "file": str(py_file.relative_to(self.backend_dir)),
                            "name": node.name,
                            "line": node.lineno,
                            "body_start": func_body_start[:200]  # –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤
                        })
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {py_file}: {e}")
        
        # –ù–∞–π—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã (—Ñ—É–Ω–∫—Ü–∏–∏ —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Å–∏–≥–Ω–∞—Ç—É—Ä–æ–π)
        for signature, functions in function_signatures.items():
            if len(functions) > 1:
                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ö–æ–∂–∏
                bodies = [f["body_start"] for f in functions]
                if len(set(bodies)) < len(bodies):  # –ï—Å—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ç–µ–ª–∞
                    duplicates.append({
                        "signature": signature,
                        "functions": functions,
                        "count": len(functions)
                    })
        
        return duplicates
    
    def find_unused_imports(self) -> List[Dict]:
        """–ù–∞–π—Ç–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã"""
        unused = []
        
        for py_file in self.backend_dir.rglob("*.py"):
            if "__pycache__" in str(py_file) or "migrations" in str(py_file):
                continue
            
            try:
                content = py_file.read_text(encoding="utf-8")
                tree = ast.parse(content)
                
                # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ –∏–º–ø–æ—Ä—Ç—ã
                imports = set()
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            imports.add(alias.name.split('.')[0])
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            imports.add(node.module.split('.')[0])
                        for alias in node.names:
                            imports.add(alias.name)
                
                # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–µ–Ω–∞
                used_names = set()
                for node in ast.walk(tree):
                    if isinstance(node, ast.Name) and not isinstance(node.ctx, ast.Store):
                        used_names.add(node.id)
                    elif isinstance(node, ast.Attribute):
                        if isinstance(node.value, ast.Name):
                            used_names.add(node.value.id)
                
                # –ù–∞–π—Ç–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã
                file_unused = []
                for imp in imports:
                    if imp not in used_names and imp not in ['sys', 'os', 'json', 'datetime', 'typing']:
                        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
                        if imp not in content.replace(f"import {imp}", "").replace(f"from {imp}", ""):
                            file_unused.append(imp)
                
                if file_unused:
                    unused.append({
                        "file": str(py_file.relative_to(self.backend_dir)),
                        "imports": file_unused
                    })
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–º–ø–æ—Ä—Ç–æ–≤ {py_file}: {e}")
        
        return unused
    
    def find_unused_functions(self) -> List[Dict]:
        """–ù–∞–π—Ç–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"""
        unused = []
        all_function_calls = set()
        
        # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ –≤—ã–∑–æ–≤—ã —Ñ—É–Ω–∫—Ü–∏–π
        for py_file in self.backend_dir.rglob("*.py"):
            if "__pycache__" in str(py_file) or "migrations" in str(py_file):
                continue
            
            try:
                content = py_file.read_text(encoding="utf-8")
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.Call):
                        if isinstance(node.func, ast.Name):
                            all_function_calls.add(node.func.id)
                        elif isinstance(node.func, ast.Attribute):
                            all_function_calls.add(node.func.attr)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—ã–∑–æ–≤–æ–≤ {py_file}: {e}")
        
        # –ù–∞–π—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –≤—ã–∑—ã–≤–∞—é—Ç—Å—è
        for py_file in self.backend_dir.rglob("*.py"):
            if "__pycache__" in str(py_file) or "migrations" in str(py_file):
                continue
            
            try:
                content = py_file.read_text(encoding="utf-8")
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∏ –º–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Å–æ–≤
                        if node.name.startswith('_') and not node.name.startswith('__'):
                            continue
                        
                        # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –º–µ—Ç–æ–¥—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤—ã–∑–≤–∞–Ω—ã —á–µ—Ä–µ–∑ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
                        if any(decorator.id == 'router' for decorator in node.decorator_list 
                               if isinstance(decorator, ast.Name)):
                            continue
                        
                        if node.name not in all_function_calls:
                            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —Ç–æ—á–∫–æ–π –≤—Ö–æ–¥–∞ (main, __init__ –∏ —Ç.–¥.)
                            if node.name not in ['main', '__init__', '__call__', 'configure', 'setup']:
                                unused.append({
                                    "file": str(py_file.relative_to(self.backend_dir)),
                                    "function": node.name,
                                    "line": node.lineno
                                })
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ—É–Ω–∫—Ü–∏–π {py_file}: {e}")
        
        return unused
    
    def find_deprecated_components(self) -> List[Dict]:
        """–ù–∞–π—Ç–∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–ø–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º, –∏–º–µ–Ω–∞–º –∏ —Ç.–¥.)"""
        deprecated = []
        
        deprecated_keywords = [
            'deprecated', 'legacy', 'old', 'unused', 'todo', 'fixme',
            'hack', 'temporary', 'temp', 'obsolete', 'remove'
        ]
        
        for py_file in self.backend_dir.rglob("*.py"):
            if "__pycache__" in str(py_file) or "migrations" in str(py_file):
                continue
            
            try:
                content = py_file.read_text(encoding="utf-8")
                lines = content.split('\n')
                
                for i, line in enumerate(lines, 1):
                    line_lower = line.lower()
                    for keyword in deprecated_keywords:
                        if keyword in line_lower:
                            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ —Å–ª—É—á–∞–π–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ
                            if any(marker in line_lower for marker in ['#', '"""', "'''"]):
                                deprecated.append({
                                    "file": str(py_file.relative_to(self.backend_dir)),
                                    "line": i,
                                    "content": line.strip()[:100],
                                    "keyword": keyword
                                })
                                break
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {py_file}: {e}")
        
        return deprecated
    
    def find_duplicated_code_blocks(self, min_lines: int = 5) -> List[Dict]:
        """–ù–∞–π—Ç–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∏ –∫–æ–¥–∞"""
        duplicates = []
        code_blocks = defaultdict(list)
        
        for py_file in self.backend_dir.rglob("*.py"):
            if "__pycache__" in str(py_file) or "migrations" in str(py_file):
                continue
            
            try:
                content = py_file.read_text(encoding="utf-8")
                lines = content.split('\n')
                
                # –ù–∞–π—Ç–∏ –±–ª–æ–∫–∏ –∫–æ–¥–∞ (–º–µ–∂–¥—É –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏ –∏–ª–∏ –æ—Ç—Å—Ç—É–ø–∞–º–∏)
                current_block = []
                current_indent = 0
                
                for i, line in enumerate(lines, 1):
                    stripped = line.strip()
                    if not stripped or stripped.startswith('#'):
                        if len(current_block) >= min_lines:
                            block_text = '\n'.join(current_block)
                            # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å (—É–±—Ä–∞—Ç—å –æ—Ç—Å—Ç—É–ø—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
                            normalized = '\n'.join(l.strip() for l in current_block if l.strip())
                            if len(normalized) > 50:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–ª–æ–∫–∞
                                code_blocks[normalized].append({
                                    "file": str(py_file.relative_to(self.backend_dir)),
                                    "start_line": i - len(current_block),
                                    "end_line": i - 1,
                                    "block": block_text
                                })
                        current_block = []
                    else:
                        current_block.append(line)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –±–ª–æ–∫–æ–≤ {py_file}: {e}")
        
        # –ù–∞–π—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã
        for block_text, occurrences in code_blocks.items():
            if len(occurrences) > 1:
                duplicates.append({
                    "block": block_text[:200],
                    "occurrences": occurrences,
                    "count": len(occurrences)
                })
        
        return duplicates
    
    def audit(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Å—Ç–∏ –ø–æ–ª–Ω—ã–π –∞—É–¥–∏—Ç –∫–æ–¥–∞"""
        logger.info("–ù–∞—á–∞–ª–æ –∞—É–¥–∏—Ç–∞ –∫–æ–¥–∞...")
        
        logger.info("–ü–æ–∏—Å–∫ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π...")
        self.duplicated_code = self.find_duplicated_functions()
        
        logger.info("–ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤...")
        self.unused_imports = self.find_unused_imports()
        
        logger.info("–ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π...")
        self.unused_functions = self.find_unused_functions()
        
        logger.info("–ü–æ–∏—Å–∫ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
        self.deprecated_components = self.find_deprecated_components()
        
        logger.info("–ü–æ–∏—Å–∫ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞...")
        duplicated_blocks = self.find_duplicated_code_blocks()
        
        return {
            "duplicated_functions": self.duplicated_code,
            "duplicated_blocks": duplicated_blocks,
            "unused_imports": self.unused_imports,
            "unused_functions": self.unused_functions,
            "deprecated_components": self.deprecated_components,
            "summary": {
                "total_duplicated_functions": len(self.duplicated_code),
                "total_duplicated_blocks": len(duplicated_blocks),
                "total_unused_imports": sum(len(u["imports"]) for u in self.unused_imports),
                "total_unused_functions": len(self.unused_functions),
                "total_deprecated": len(self.deprecated_components)
            }
        }
    
    def generate_report(self, audit_results: Dict[str, Any]) -> str:
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –≤ Markdown"""
        output = []
        
        output.append("# –û—Ç—á–µ—Ç –∞—É–¥–∏—Ç–∞ –∫–æ–¥–∞ AARD\n")
        output.append(f"*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {Path(__file__).stat().st_mtime}*\n\n")
        
        summary = audit_results.get("summary", {})
        output.append("## –°–≤–æ–¥–∫–∞\n\n")
        output.append(f"- –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π: {summary.get('total_duplicated_functions', 0)}\n")
        output.append(f"- –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞: {summary.get('total_duplicated_blocks', 0)}\n")
        output.append(f"- –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤: {summary.get('total_unused_imports', 0)}\n")
        output.append(f"- –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π: {summary.get('total_unused_functions', 0)}\n")
        output.append(f"- –£—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {summary.get('total_deprecated', 0)}\n\n")
        
        # –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
        if audit_results.get("duplicated_functions"):
            output.append("## –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏\n\n")
            for dup in audit_results["duplicated_functions"][:20]:  # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –≤—ã–≤–æ–¥
                output.append(f"### {dup['signature']}\n")
                output.append(f"–ù–∞–π–¥–µ–Ω–æ –≤ {dup['count']} –º–µ—Å—Ç–∞—Ö:\n")
                for func in dup["functions"]:
                    output.append(f"- `{func['file']}:{func['line']}` - {func['name']}\n")
                output.append("\n")
        
        # –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã
        if audit_results.get("unused_imports"):
            output.append("## –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã\n\n")
            for item in audit_results["unused_imports"][:30]:
                output.append(f"### {item['file']}\n")
                output.append(f"–ò–º–ø–æ—Ä—Ç—ã: {', '.join(item['imports'])}\n\n")
        
        # –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
        if audit_results.get("unused_functions"):
            output.append("## –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏\n\n")
            for func in audit_results["unused_functions"][:30]:
                output.append(f"- `{func['file']}:{func['line']}` - {func['function']}\n")
            output.append("\n")
        
        # –£—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        if audit_results.get("deprecated_components"):
            output.append("## –£—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n\n")
            for comp in audit_results["deprecated_components"][:30]:
                output.append(f"- `{comp['file']}:{comp['line']}` - {comp['keyword']}\n")
                output.append(f"  {comp['content']}\n\n")
        
        return "\n".join(output)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 70)
    print(" –ê—É–¥–∏—Ç –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞ AARD")
    print("=" * 70 + "\n")
    
    auditor = CodeAuditor()
    
    try:
        audit_results = auditor.audit()
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON
        json_file = auditor.project_root / "docs" / "TECHNICAL_DEBT.json"
        json_file.parent.mkdir(parents=True, exist_ok=True)
        json_file.write_text(json.dumps(audit_results, indent=2, ensure_ascii=False), encoding="utf-8")
        
        # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –≤ Markdown
        report = auditor.generate_report(audit_results)
        md_file = auditor.project_root / "docs" / "TECHNICAL_DEBT.md"
        md_file.write_text(report, encoding="utf-8")
        
        print(f"\n‚úÖ –ê—É–¥–∏—Ç –∑–∞–≤–µ—Ä—à–µ–Ω:")
        print(f"   JSON: {json_file}")
        print(f"   Markdown: {md_file}")
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        summary = audit_results.get("summary", {})
        for key, value in summary.items():
            print(f"   - {key}: {value}")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞—É–¥–∏—Ç–∞: {e}", exc_info=True)
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

