"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
–≠—Ç–∞–ø 9.2.1: –†–µ–æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
"""
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

# Add backend to path
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

from app.core.logging_config import LoggingConfig

logger = LoggingConfig.get_logger(__name__)


class DocsReorganizer:
    """–†–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
    
    def __init__(self, dry_run: bool = True):
        self.project_root = backend_dir.parent
        self.docs_dir = self.project_root / "docs"
        self.archive_dir = self.docs_dir / "archive"
        self.guides_dir = self.docs_dir / "guides"
        self.dry_run = dry_run
        self.moved_files = []
        self.merged_files = []
        
    def categorize_docs(self) -> Dict[str, List[Path]]:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã"""
        categories = {
            "implementation_status": [],
            "test_results": [],
            "fixes": [],
            "guides": [],
            "architecture": [],
            "other": []
        }
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏
        keywords = {
            "implementation_status": ["implementation", "status", "complete", "progress"],
            "test_results": ["test", "result", "testing"],
            "fixes": ["fix", "fixes", "error", "bug"],
            "guides": ["guide", "setup", "howto", "tutorial"],
            "architecture": ["architecture", "design", "system"]
        }
        
        for md_file in self.docs_dir.glob("*.md"):
            if md_file.name == "README.md":
                continue
            
            file_name_lower = md_file.stem.lower()
            categorized = False
            
            for category, category_keywords in keywords.items():
                if any(kw in file_name_lower for kw in category_keywords):
                    categories[category].append(md_file)
                    categorized = True
                    break
            
            if not categorized:
                categories["other"].append(md_file)
        
        return categories
    
    def create_docs_index(self) -> str:
        """–°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        categories = self.categorize_docs()
        
        output = []
        output.append("# –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è AARD\n\n")
        output.append(f"*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {datetime.now().strftime('%Y-%m-%d')}*\n\n")
        
        output.append("## –ù–∞–≤–∏–≥–∞—Ü–∏—è\n\n")
        output.append("- [–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞](#—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞)\n")
        output.append("- [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)\n")
        output.append("- [–°—Ç–∞—Ç—É—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏](#—Å—Ç–∞—Ç—É—Å-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)\n")
        output.append("- [–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è](#—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)\n")
        output.append("- [–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è](#–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è)\n")
        output.append("- [–ü—Ä–æ—á–µ–µ](#–ø—Ä–æ—á–µ–µ)\n\n")
        
        # –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
        if categories["guides"] or self.guides_dir.exists():
            output.append("## –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞\n\n")
            output.append("–î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ —Å–∏—Å—Ç–µ–º—ã.\n\n")
            output.append("### –û—Å–Ω–æ–≤–Ω—ã–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞\n\n")
            
            guide_files = list(self.guides_dir.glob("*.md")) if self.guides_dir.exists() else []
            for guide_file in sorted(guide_files):
                guide_name = guide_file.stem.replace("_", " ").title()
                output.append(f"- [{guide_name}](guides/{guide_file.name})\n")
            
            output.append("\n### –î—Ä—É–≥–∏–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞\n\n")
            for doc in categories["guides"]:
                output.append(f"- [{doc.stem}]({doc.name})\n")
            output.append("\n")
        
        # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        if categories["architecture"]:
            output.append("## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n\n")
            for doc in sorted(categories["architecture"]):
                output.append(f"- [{doc.stem}]({doc.name})\n")
            output.append("\n")
        
        # –°—Ç–∞—Ç—É—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        if categories["implementation_status"]:
            output.append("## –°—Ç–∞—Ç—É—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏\n\n")
            for doc in sorted(categories["implementation_status"]):
                output.append(f"- [{doc.stem}]({doc.name})\n")
            output.append("\n")
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        if categories["test_results"]:
            output.append("## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n\n")
            for doc in sorted(categories["test_results"]):
                output.append(f"- [{doc.stem}]({doc.name})\n")
            output.append("\n")
        
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        if categories["fixes"]:
            output.append("## –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n\n")
            for doc in sorted(categories["fixes"]):
                output.append(f"- [{doc.stem}]({doc.name})\n")
            output.append("\n")
        
        # –ü—Ä–æ—á–µ–µ
        if categories["other"]:
            output.append("## –ü—Ä–æ—á–µ–µ\n\n")
            for doc in sorted(categories["other"]):
                output.append(f"- [{doc.stem}]({doc.name})\n")
            output.append("\n")
        
        # –ê—Ä—Ö–∏–≤
        if self.archive_dir.exists():
            archive_count = len(list(self.archive_dir.glob("*.md")))
            output.append(f"## –ê—Ä—Ö–∏–≤\n\n")
            output.append(f"–£—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã –≤ [archive/](archive/) ({archive_count} —Ñ–∞–π–ª–æ–≤)\n\n")
        
        return "\n".join(output)
    
    def move_to_archive(self, file_path: Path) -> bool:
        """–ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —Ñ–∞–π–ª –≤ –∞—Ä—Ö–∏–≤"""
        if not self.archive_dir.exists():
            self.archive_dir.mkdir(parents=True, exist_ok=True)
        
        target = self.archive_dir / file_path.name
        
        # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –∞—Ä—Ö–∏–≤–µ, –¥–æ–±–∞–≤–∏—Ç—å —Å—É—Ñ—Ñ–∏–∫—Å
        counter = 1
        while target.exists():
            target = self.archive_dir / f"{file_path.stem}_{counter}{file_path.suffix}"
            counter += 1
        
        if not self.dry_run:
            shutil.move(str(file_path), str(target))
        
        self.moved_files.append({
            "from": str(file_path.relative_to(self.project_root)),
            "to": str(target.relative_to(self.project_root))
        })
        
        return True
    
    def merge_related_docs(self) -> List[Dict]:
        """–û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"""
        merged = []
        
        # –ù–∞–π—Ç–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, TEST_RESULTS.md –∏ TEST_RESULTS_LOGS.md)
        test_results_files = list(self.docs_dir.glob("*TEST*RESULT*.md"))
        if len(test_results_files) > 1:
            # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª
            main_file = test_results_files[0]
            merged_content = [main_file.read_text(encoding="utf-8")]
            
            for other_file in test_results_files[1:]:
                content = other_file.read_text(encoding="utf-8")
                merged_content.append(f"\n\n---\n\n## –ò–∑ {other_file.name}\n\n{content}")
                
                if not self.dry_run:
                    self.move_to_archive(other_file)
                
                merged.append({
                    "merged_from": str(other_file.relative_to(self.project_root)),
                    "merged_to": str(main_file.relative_to(self.project_root))
                })
            
            if not self.dry_run and merged:
                main_file.write_text("\n".join(merged_content), encoding="utf-8")
        
        return merged
    
    def reorganize(self) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é"""
        logger.info("–ù–∞—á–∞–ª–æ —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...")
        
        # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        logger.info("–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        merged = self.merge_related_docs()
        
        # –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –∞—Ä—Ö–∏–≤
        logger.info("–ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å –¥–∞—Ç–∞–º–∏ –≤ –ø—Ä–æ—à–ª–æ–º –∏–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã)
        categories = self.categorize_docs()
        
        # –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å
        logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...")
        index_content = self.create_docs_index()
        
        if not self.dry_run:
            index_file = self.docs_dir / "README.md"
            index_file.write_text(index_content, encoding="utf-8")
        
        return {
            "merged_files": merged,
            "moved_files": self.moved_files,
            "index_created": True,
            "summary": {
                "merged_count": len(merged),
                "moved_count": len(self.moved_files)
            }
        }


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description="–†–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏")
    parser.add_argument("--dry-run", action="store_true", default=True,
                       help="–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –±—É–¥–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–æ, –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å")
    parser.add_argument("--execute", action="store_true",
                       help="–í—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é dry-run)")
    args = parser.parse_args()
    
    dry_run = not args.execute
    
    print("=" * 70)
    print(" –†–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ AARD")
    print("=" * 70 + "\n")
    
    if dry_run:
        print("‚ö†Ô∏è  –†–ï–ñ–ò–ú DRY-RUN: –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã\n")
    else:
        print("‚ö†Ô∏è  –†–ï–ñ–ò–ú –í–´–ü–û–õ–ù–ï–ù–ò–Ø: –∏–∑–º–µ–Ω–µ–Ω–∏—è –±—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã!\n")
    
    reorganizer = DocsReorganizer(dry_run=dry_run)
    
    try:
        results = reorganizer.reorganize()
        
        print(f"\n‚úÖ –†–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        summary = results.get("summary", {})
        print(f"   - –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {summary.get('merged_count', 0)}")
        print(f"   - –ü–µ—Ä–µ–º–µ—â–µ–Ω–æ –≤ –∞—Ä—Ö–∏–≤: {summary.get('moved_count', 0)}")
        print(f"   - –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω: {results.get('index_created', False)}")
        
        if dry_run:
            print("\nüí° –î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å —Ñ–ª–∞–≥–æ–º --execute")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏: {e}", exc_info=True)
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

