"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞
–≠—Ç–∞–ø 9.1.3: –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª
"""
import ast
import re
import shutil
import sys
from pathlib import Path
from typing import Dict, List

# Add backend to path
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

from app.core.logging_config import LoggingConfig

logger = LoggingConfig.get_logger(__name__)


class DuplicateConsolidator:
    """–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞"""
    
    def __init__(self, dry_run: bool = True):
        self.backend_dir = backend_dir
        self.dry_run = dry_run
        self.consolidated_functions = []
        
    def consolidate_print_separator(self) -> Dict:
        """–ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é print_separator"""
        # –ù–∞–π—Ç–∏ –≤—Å–µ —Ñ–∞–π–ª—ã —Å print_separator
        files_with_separator = []
        
        for py_file in self.backend_dir.rglob("*.py"):
            if "__pycache__" in str(py_file) or "migrations" in str(py_file):
                continue
            
            try:
                content = py_file.read_text(encoding="utf-8")
                if "def print_separator" in content:
                    files_with_separator.append(py_file)
            except:
                continue
        
        # –ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –∏–º–ø–æ—Ä—Ç –∏–∑ utils
        replacements = []
        for file_path in files_with_separator:
            try:
                content = file_path.read_text(encoding="utf-8")
                
                # –ù–∞–π—Ç–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
                pattern = r'def print_separator\([^)]*\):.*?(?=\n\ndef|\nclass|\Z)'
                match = re.search(pattern, content, re.DOTALL)
                
                if match:
                    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –µ—Å—Ç—å –ª–∏ —É–∂–µ –∏–º–ø–æ—Ä—Ç –∏–∑ utils
                    if "from app.core.utils import" not in content and \
                       "from app.core import utils" not in content:
                        # –î–æ–±–∞–≤–∏—Ç—å –∏–º–ø–æ—Ä—Ç
                        import_line = "from app.core.utils import print_separator\n"
                        
                        # –ù–∞–π—Ç–∏ –º–µ—Å—Ç–æ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ (–ø–æ—Å–ª–µ –¥—Ä—É–≥–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤)
                        import_section_end = 0
                        for i, line in enumerate(content.split('\n')):
                            if line.strip().startswith('import ') or line.strip().startswith('from '):
                                import_section_end = i + 1
                        
                        lines = content.split('\n')
                        if import_section_end > 0:
                            lines.insert(import_section_end, import_line)
                        else:
                            lines.insert(0, import_line)
                        
                        content = '\n'.join(lines)
                    
                    # –£–¥–∞–ª–∏—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
                    new_content = re.sub(pattern, '', content, flags=re.DOTALL)
                    
                    if new_content != content:
                        replacements.append({
                            "file": str(file_path.relative_to(self.backend_dir)),
                            "action": "replace_print_separator"
                        })
                        
                        if not self.dry_run:
                            file_path.write_text(new_content, encoding="utf-8")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path}: {e}")
        
        return {
            "function": "print_separator",
            "files_updated": len(replacements),
            "replacements": replacements
        }
    
    def consolidate_init_servers(self) -> Dict:
        """–ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é init_servers"""
        # –ù–∞–π—Ç–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ init_servers
        files_with_init = []
        
        for py_file in self.backend_dir.rglob("*.py"):
            if "__pycache__" in str(py_file) or "migrations" in str(py_file):
                continue
            
            try:
                content = py_file.read_text(encoding="utf-8")
                if "def init_servers" in content:
                    files_with_init.append(py_file)
            except:
                continue
        
        # –û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ñ–∞–π–ª (scripts/init_ollama_servers.py), –æ—Å—Ç–∞–ª—å–Ω—ã–µ —É–¥–∞–ª–∏—Ç—å –∏–ª–∏ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –∏–º–ø–æ—Ä—Ç
        if len(files_with_init) > 1:
            main_file = None
            duplicates = []
            
            for file_path in files_with_init:
                if "scripts/init_ollama_servers.py" in str(file_path) or \
                   "init_ollama_servers.py" in str(file_path):
                    main_file = file_path
                else:
                    duplicates.append(file_path)
            
            if main_file:
                # –£–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–ª–∏ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –∏–º–ø–æ—Ä—Ç
                for dup_file in duplicates:
                    if not self.dry_run:
                        # –ú–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª –∏–ª–∏ –∑–∞–º–µ–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ –∏–º–ø–æ—Ä—Ç
                        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ø–æ–º–µ—Ç–∏–º –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
                        pass
                    
                    self.consolidated_functions.append({
                        "file": str(dup_file.relative_to(self.backend_dir)),
                        "action": "remove_duplicate_init_servers"
                    })
        
        return {
            "function": "init_servers",
            "files_updated": len(self.consolidated_functions)
        }
    
    def consolidate(self, audit_results_path: Path) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—É–¥–∏—Ç–∞"""
        logger.info("–ù–∞—á–∞–ª–æ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞...")
        
        # –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å print_separator
        logger.info("–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è print_separator...")
        separator_result = self.consolidate_print_separator()
        
        # –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å init_servers
        logger.info("–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è init_servers...")
        init_result = self.consolidate_init_servers()
        
        return {
            "print_separator": separator_result,
            "init_servers": init_result,
            "summary": {
                "total_consolidated": len(self.consolidated_functions)
            }
        }


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description="–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞")
    parser.add_argument("--dry-run", action="store_true", default=True,
                       help="–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –±—É–¥–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–æ, –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å")
    parser.add_argument("--execute", action="store_true",
                       help="–í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—é (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é dry-run)")
    args = parser.parse_args()
    
    dry_run = not args.execute
    
    print("=" * 70)
    print(" –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞ –ø—Ä–æ–µ–∫—Ç–∞ AARD")
    print("=" * 70 + "\n")
    
    if dry_run:
        print("‚ö†Ô∏è  –†–ï–ñ–ò–ú DRY-RUN: –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã\n")
    else:
        print("‚ö†Ô∏è  –†–ï–ñ–ò–ú –í–´–ü–û–õ–ù–ï–ù–ò–Ø: –∏–∑–º–µ–Ω–µ–Ω–∏—è –±—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã!\n")
    
    consolidator = DuplicateConsolidator(dry_run=dry_run)
    
    # –ü—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∞—É–¥–∏—Ç–∞
    audit_results_path = consolidator.backend_dir.parent / "docs" / "TECHNICAL_DEBT.json"
    
    if not audit_results_path.exists():
        print(f"‚ùå –§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—É–¥–∏—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {audit_results_path}")
        print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python scripts/code_audit.py")
        sys.exit(1)
    
    try:
        results = consolidator.consolidate(audit_results_path)
        
        print(f"\n‚úÖ –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        print(f"   - print_separator: {results['print_separator']['files_updated']} —Ñ–∞–π–ª–æ–≤")
        print(f"   - init_servers: {results['init_servers']['files_updated']} —Ñ–∞–π–ª–æ–≤")
        
        if dry_run:
            print("\nüí° –î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å —Ñ–ª–∞–≥–æ–º --execute")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏: {e}", exc_info=True)
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

